{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a6c4d7",
   "metadata": {},
   "source": [
    "EDA com objetivo de entender profundamente o dataset, suas características e peculiaridades para que possa ser planejada a amostragem de forma inteligente e eficaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependências\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7lhxdke0dr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from datasets) (2.3.2)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.34.6-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (4.15.0)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Downloading charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached datasets-4.1.0-py3-none-any.whl (503 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.15-cp310-cp310-macosx_11_0_arm64.whl (468 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.4-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-macosx_11_0_arm64.whl (89 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-macosx_11_0_arm64.whl (46 kB)\n",
      "Downloading huggingface_hub-0.34.6-py3-none-any.whl (562 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.6/562.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-macosx_11_0_arm64.whl (43 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl (207 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, urllib3, pyyaml, propcache, multidict, idna, hf-xet, frozenlist, dill, charset_normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [datasets]/21\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 datasets-4.1.0 dill-0.4.0 frozenlist-1.7.0 hf-xet-1.1.10 huggingface-hub-0.34.6 idna-3.10 multidict-6.6.4 multiprocess-0.70.16 propcache-0.3.2 pyyaml-6.0.2 requests-2.32.5 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1b39a1cf6d4b3f87eabf8d7e066b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/428 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87efaea70a3c440cb4b06da6ecf70a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedc885e330146adaba2512a2a94158b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7357 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregar o dataset\n",
    "dataset = load_dataset(\"eliasjacob/simulados_enem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1696ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo o dataset para pandas dataframe para manipulação mais fácil\n",
    "df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46e489da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "Ciências da Natureza    2050\n",
      "Ciências Humanas        1947\n",
      "Linguagens e Códigos    1737\n",
      "Matemática              1623\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Distribuição das disciplinas\n",
    "print(df['dataset'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb577215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question       0\n",
      "true_answer    0\n",
      "question_id    0\n",
      "dataset        0\n",
      "split          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Análise de nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29fxbmljf4x",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VISÃO GERAL DO DATASET ===\n",
      "Formato: (7357, 5)\n",
      "Uso de memória: 13.32 MB\n",
      "\n",
      "Tipos de colunas:\n",
      "object    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Primeiras linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>true_answer</th>\n",
       "      <th>question_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEXTO DE REFERÊNCIA: Nos desfiles das escolas ...</td>\n",
       "      <td>36 m²</td>\n",
       "      <td>512bec889180958c6b2e1c395931312ecc916a2039930d...</td>\n",
       "      <td>Matemática</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEXTO DE REFERÊNCIA: A companhia de energia el...</td>\n",
       "      <td>V(x) = 3x – 288</td>\n",
       "      <td>15da8d828a79fd53c164ac141d0ff2da49b16ade1618ae...</td>\n",
       "      <td>Matemática</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEXTO DE REFERÊNCIA: A forma mais simples e an...</td>\n",
       "      <td>hidratação do eteno</td>\n",
       "      <td>511f342e3329057bc6c74ff0f0c36dae381f437c3d5350...</td>\n",
       "      <td>Ciências da Natureza</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEXTO DE REFERÊNCIA: Cingapura é universalment...</td>\n",
       "      <td>projeção no mercado global</td>\n",
       "      <td>cd526d0e6d0406f30dea65939e5d2e14efebffaf28b334...</td>\n",
       "      <td>Ciências Humanas</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Texto de referência: Invocação de São Mateus (...</td>\n",
       "      <td>Estilo religioso e dramático, com clara demons...</td>\n",
       "      <td>8f97982035c3c9f4444974669aed8466b9b96a6c4ebf2d...</td>\n",
       "      <td>Linguagens e Códigos</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  TEXTO DE REFERÊNCIA: Nos desfiles das escolas ...   \n",
       "1  TEXTO DE REFERÊNCIA: A companhia de energia el...   \n",
       "2  TEXTO DE REFERÊNCIA: A forma mais simples e an...   \n",
       "3  TEXTO DE REFERÊNCIA: Cingapura é universalment...   \n",
       "4  Texto de referência: Invocação de São Mateus (...   \n",
       "\n",
       "                                         true_answer  \\\n",
       "0                                              36 m²   \n",
       "1                                    V(x) = 3x – 288   \n",
       "2                                hidratação do eteno   \n",
       "3                         projeção no mercado global   \n",
       "4  Estilo religioso e dramático, com clara demons...   \n",
       "\n",
       "                                         question_id               dataset  \\\n",
       "0  512bec889180958c6b2e1c395931312ecc916a2039930d...            Matemática   \n",
       "1  15da8d828a79fd53c164ac141d0ff2da49b16ade1618ae...            Matemática   \n",
       "2  511f342e3329057bc6c74ff0f0c36dae381f437c3d5350...  Ciências da Natureza   \n",
       "3  cd526d0e6d0406f30dea65939e5d2e14efebffaf28b334...      Ciências Humanas   \n",
       "4  8f97982035c3c9f4444974669aed8466b9b96a6c4ebf2d...  Linguagens e Códigos   \n",
       "\n",
       "   split  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Estrutura do dataset e informação dos dados\n",
    "print(\"=== VISÃO GERAL DO DATASET ===\")\n",
    "print(f\"Formato: {df.shape}\")\n",
    "print(f\"Uso de memória: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nTipos de colunas:\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "boyw4pfhlnc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QUALIDADE DOS DADOS ===\n",
      "Valores ausentes por coluna:\n",
      "Empty DataFrame\n",
      "Columns: [Contagem dos valores ausentes, Valores ausentes %]\n",
      "Index: []\n",
      "\n",
      "Linhas duplicadas: 0\n",
      "Valores únicos por coluna:\n",
      "question: 7357 valores únicos (100.0%)\n",
      "true_answer: 6678 valores únicos (90.8%)\n",
      "question_id: 7357 valores únicos (100.0%)\n",
      "dataset: 4 valores únicos (0.1%)\n",
      "split: 3 valores únicos (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# 2. QUALIDADE DOS DADOS E ANÁLISE DE VALORES ÚNICOS\n",
    "print(\"=== QUALIDADE DOS DADOS ===\")\n",
    "print(\"Valores ausentes por coluna:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Contagem dos valores ausentes': missing_data,\n",
    "    'Valores ausentes %': missing_percent\n",
    "}).sort_values('Valores ausentes %', ascending=False)\n",
    "print(missing_df[missing_df['Contagem dos valores ausentes'] > 0])\n",
    "\n",
    "print(\"\\nLinhas duplicadas:\", df.duplicated().sum())\n",
    "print(\"Valores únicos por coluna:\")\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"{col}: {unique_count} valores únicos ({unique_count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ztjft16q5y",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE DA VARIÁVEL ALVO ===\n",
      "Colunas potenciais encontradas: ['true_answer']\n",
      "\n",
      "Distribuição de true_answer:\n",
      "true_answer\n",
      "\"Sou aquela velhinha\" e \"Fiz uma tatuagem\"                                                                   1\n",
      "((A – B) ∩ C) ∩ ((A – D) ∪ E)                                                                                1\n",
      "(-1, 3)                                                                                                      1\n",
      "(-2, 1)                                                                                                      1\n",
      "(1, 2)                                                                                                       1\n",
      "                                                                                                            ..\n",
      "“Tu é labirinto” e “Me perdi”                                                                                1\n",
      "“[…] o longa entrega uma fusão de real e fictício que por vezes parece ter medo de ser mais crítico […]”.    1\n",
      "√13 cm                                                                                                       1\n",
      "√3/2                                                                                                         1\n",
      "√φ                                                                                                           1\n",
      "Name: count, Length: 6678, dtype: int64\n",
      "Distribuição de classes:\n",
      "true_answer\n",
      "IV                                               0.004\n",
      "II                                               0.003\n",
      "4                                                0.003\n",
      "3                                                0.003\n",
      "III                                              0.003\n",
      "                                                 ...  \n",
      "x^2 - x - 600 = 0                                0.000\n",
      "ClO2                                             0.000\n",
      "5577                                             0.000\n",
      "dependência do capital financeiro estrangeiro    0.000\n",
      "29%                                              0.000\n",
      "Name: proportion, Length: 6678, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3. Análise da variável alvo\n",
    "print(\"=== ANÁLISE DA VARIÁVEL ALVO ===\")\n",
    "\n",
    "# Identificando colunas que podem ser a variável alvo\n",
    "potential_targets = []\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in ['answer', 'correct', 'target', 'label', 'score', 'result']):\n",
    "        potential_targets.append(col)\n",
    "\n",
    "if potential_targets:\n",
    "    print(\"Colunas potenciais encontradas:\", potential_targets)\n",
    "    for target in potential_targets:\n",
    "        print(f\"\\nDistribuição de {target}:\")\n",
    "        print(df[target].value_counts().sort_index())\n",
    "        if df[target].dtype in ['object', 'category']:\n",
    "            print(f\"Distribuição de classes:\")\n",
    "            print(df[target].value_counts(normalize=True).round(3))\n",
    "else:\n",
    "    print(\"Nenhuma coluna alvo óbvia encontrada. Mostrando todas as colunas:\")\n",
    "    print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mlzirdpvd5m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE DE FEATURES TEXTUAIS ===\n",
      "\n",
      "question:\n",
      "  - Comprimento médio: 795.9 caracteres\n",
      "  - Comprimento mínimo: 42\n",
      "  - Comprimento máximo: 5889\n",
      "  - Valores únicos: 7357\n",
      "  - Valores de exemplo:\n",
      "    [1] TEXTO DE REFERÊNCIA: Nos desfiles das escolas de samba do Rio de Janeiro, é cada vez mais comum obse...\n",
      "    [2] TEXTO DE REFERÊNCIA: A companhia de energia elétrica de uma cidade realiza a cobrança do forneciment...\n",
      "\n",
      "true_answer:\n",
      "  - Comprimento médio: 33.1 caracteres\n",
      "  - Comprimento mínimo: 1\n",
      "  - Comprimento máximo: 241\n",
      "  - Valores únicos: 6678\n",
      "  - Valores de exemplo:\n",
      "    [1] 36 m²\n",
      "    [2] V(x) = 3x – 288\n",
      "\n",
      "question_id:\n",
      "  - Comprimento médio: 128.0 caracteres\n",
      "  - Comprimento mínimo: 128\n",
      "  - Comprimento máximo: 128\n",
      "  - Valores únicos: 7357\n",
      "  - Valores de exemplo:\n",
      "    [1] 512bec889180958c6b2e1c395931312ecc916a2039930da113eb5ed196ac010dcb7fe06e473cd64b056438961bf09bfe7b46...\n",
      "    [2] 15da8d828a79fd53c164ac141d0ff2da49b16ade1618ae381b46765290af4f8226c5439dbf8beadf9923f3d6ccf68b21a248...\n",
      "\n",
      "dataset:\n",
      "  - Comprimento médio: 16.7 caracteres\n",
      "  - Comprimento mínimo: 10\n",
      "  - Comprimento máximo: 20\n",
      "  - Valores únicos: 4\n",
      "  - Valores de exemplo:\n",
      "    [1] Matemática\n",
      "    [2] Matemática\n",
      "\n",
      "split:\n",
      "  - Comprimento médio: 4.9 caracteres\n",
      "  - Comprimento mínimo: 4\n",
      "  - Comprimento máximo: 5\n",
      "  - Valores únicos: 3\n",
      "  - Valores de exemplo:\n",
      "    [1] train\n",
      "    [2] train\n",
      "\n",
      "question - Contagem de palavras:\n",
      "  Média de palavras: 130.5\n",
      "  Mínimo de palavras: 8\n",
      "  Máximo de palavras: 614\n",
      "\n",
      "true_answer - Contagem de palavras:\n",
      "  Média de palavras: 5.1\n",
      "  Mínimo de palavras: 1\n",
      "  Máximo de palavras: 34\n",
      "\n",
      "question_id - Contagem de palavras:\n",
      "  Média de palavras: 1.0\n",
      "  Mínimo de palavras: 1\n",
      "  Máximo de palavras: 1\n",
      "\n",
      "dataset - Contagem de palavras:\n",
      "  Média de palavras: 2.3\n",
      "  Mínimo de palavras: 1\n",
      "  Máximo de palavras: 3\n",
      "\n",
      "split - Contagem de palavras:\n",
      "  Média de palavras: 1.0\n",
      "  Mínimo de palavras: 1\n",
      "  Máximo de palavras: 1\n"
     ]
    }
   ],
   "source": [
    "# 4. Análise de features textuais\n",
    "print(\"=== ANÁLISE DE FEATURES TEXTUAIS ===\")\n",
    "\n",
    "text_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in text_columns:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  - Comprimento médio: {df[col].str.len().mean():.1f} caracteres\")\n",
    "        print(f\"  - Comprimento mínimo: {df[col].str.len().min()}\")\n",
    "        print(f\"  - Comprimento máximo: {df[col].str.len().max()}\")\n",
    "        print(f\"  - Valores únicos: {df[col].nunique()}\")\n",
    "\n",
    "        # Valores de exemplo\n",
    "        print(f\"  - Valores de exemplo:\")\n",
    "        for i, sample in enumerate(df[col].dropna().head(2)):\n",
    "            print(f\"    [{i+1}] {str(sample)[:100]}{'...' if len(str(sample)) > 100 else ''}\")\n",
    "\n",
    "# Contagem de palavras\n",
    "import re\n",
    "def count_words(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(re.findall(r'\\b\\w+\\b', str(text)))\n",
    "\n",
    "for col in text_columns:\n",
    "    if col in df.columns:\n",
    "        word_counts = df[col].apply(count_words)\n",
    "        print(f\"\\n{col} - Contagem de palavras:\")\n",
    "        print(f\"  Média de palavras: {word_counts.mean():.1f}\")\n",
    "        print(f\"  Mínimo de palavras: {word_counts.min()}\")\n",
    "        print(f\"  Máximo de palavras: {word_counts.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "v3g902lrxkc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE DE FEATURES NUMÉRICAS ===\n",
      "Sem colunas numéricas encontradas.\n"
     ]
    }
   ],
   "source": [
    "# 5. Análise de features numéricas\n",
    "print(\"=== ANÁLISE DE FEATURES NUMÉRICAS ===\")\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns\n",
    "if len(numerical_columns) > 0:\n",
    "    print(\"Estatísticas das colunas numéricas:\")\n",
    "    print(df[numerical_columns].describe())\n",
    "    \n",
    "    # Checando outliers usando o método IQR\n",
    "    print(\"\\nDetecção de outliers (método IQR):\")\n",
    "    for col in numerical_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        print(f\"{col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"Sem colunas numéricas encontradas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1vs4fxz0kb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE DE CORRELAÇÃO ===\n"
     ]
    }
   ],
   "source": [
    "# 6. Análise de correlação\n",
    "print(\"=== ANÁLISE DE CORRELAÇÃO ===\")\n",
    "\n",
    "if len(numerical_columns) > 1:\n",
    "    correlation_matrix = df[numerical_columns].corr()\n",
    "    print(\"Matriz de correlação:\")\n",
    "    print(correlation_matrix)\n",
    "    \n",
    "    # Encontrar features altamente correlacionadas\n",
    "    print(\"\\nPares de features altamente correlacionadas (|correlação| > 0.7):\")\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_val = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_val) > 0.7:\n",
    "                print(f\"{correlation_matrix.columns[i]} - {correlation_matrix.columns[j]}: {corr_val:.3f}\")\n",
    "\n",
    "# Cria um mapa de calor de correlação se tivermos dados numéricos\n",
    "if len(numerical_columns) > 1:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True)\n",
    "    plt.title('Mapa de Calor de Correlação entre Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88hgsz7z4ms",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE DE DESBALANCEAMENTO DE CLASSES ===\n",
      "\n",
      "dataset distribuição:\n",
      "  Ciências da Natureza: 2050 (27.9%)\n",
      "  Ciências Humanas: 1947 (26.5%)\n",
      "  Linguagens e Códigos: 1737 (23.6%)\n",
      "  Matemática: 1623 (22.1%)\n",
      "  Razão de desbalanceamento: 1.26:1\n",
      "\n",
      "split distribuição:\n",
      "  train: 5885 (80.0%)\n",
      "  test: 737 (10.0%)\n",
      "  valid: 735 (10.0%)\n",
      "  Razão de desbalanceamento: 8.01:1\n",
      "Alerta: Desbalanceamento de classes detectado!\n"
     ]
    }
   ],
   "source": [
    "# 7. Desbalanceamento de classes\n",
    "print(\"=== ANÁLISE DE DESBALANCEAMENTO DE CLASSES ===\")\n",
    "\n",
    "# Verificando desbalanceamento de classes nas colunas categóricas\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_columns:\n",
    "    if df[col].nunique() < 20:  # Apenas analisar colunas com número razoável de categorias\n",
    "        print(f\"\\n{col} distribuição:\")\n",
    "        value_counts = df[col].value_counts()\n",
    "        value_props = df[col].value_counts(normalize=True)\n",
    "        \n",
    "        for val in value_counts.index:\n",
    "            print(f\"  {val}: {value_counts[val]} ({value_props[val]:.1%})\")\n",
    "\n",
    "        # Calcular a razão de desbalanceamento\n",
    "        max_class = value_counts.max()\n",
    "        min_class = value_counts.min()\n",
    "        imbalance_ratio = max_class / min_class if min_class > 0 else float('inf')\n",
    "        print(f\"  Razão de desbalanceamento: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "        if imbalance_ratio > 5:\n",
    "            print(f\"Alerta: Desbalanceamento de classes detectado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3gy5gh3p6zk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETECÇÃO DE DATA LEAKAGE ===\n",
      "Fontes potenciais de data leakage encontradas:\n",
      "question: Identificador único (100% valores únicos)\n",
      "question_id: Nome de coluna suspeito\n",
      "question_id: Identificador único (100% valores únicos)\n"
     ]
    }
   ],
   "source": [
    "# 8. Detecção de Data Leakage\n",
    "print(\"=== DETECÇÃO DE DATA LEAKAGE ===\")\n",
    "\n",
    "# Verificar features que podem causar data leakage\n",
    "suspicious_keywords = ['id', 'key', 'index', 'uuid', 'timestamp', 'created', 'updated', 'modified']\n",
    "potential_leakage = []\n",
    "\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    \n",
    "    # Verificar nomes de colunas suspeitas\n",
    "    if any(keyword in col_lower for keyword in suspicious_keywords):\n",
    "        potential_leakage.append((col, \"Nome de coluna suspeito\"))\n",
    "\n",
    "    # Verificar colunas com muitos valores únicos (potenciais IDs)\n",
    "    if df[col].nunique() == len(df):\n",
    "        potential_leakage.append((col, \"Identificador único (100% valores únicos)\"))\n",
    "\n",
    "    # Verificar colunas com alta cardinalidade\n",
    "    elif df[col].nunique() / len(df) > 0.95:\n",
    "        potential_leakage.append((col, f\"Alta cardinalidade ({df[col].nunique()/len(df):.1%} únicos)\"))\n",
    "\n",
    "if potential_leakage:\n",
    "    print(\"Fontes potenciais de data leakage encontradas:\")\n",
    "    for col, reason in potential_leakage:\n",
    "        print(f\"{col}: {reason}\")\n",
    "else:\n",
    "    print(\"Nenhuma fonte óbvia de data leakage detectada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "gwg395u9ya",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AMOSTRAGEM E ESTRATÉGIA DE SUBCONJUNTO ===\n",
      "Tamanho do conjunto de dados: 7,357 linhas\n",
      "Uso de memória: 19.5 MB\n",
      "Amostra de 1,000 linhas = 13.6% do conjunto de dados\n",
      "Amostra de 5,000 linhas = 68.0% do conjunto de dados\n",
      "\n",
      "RECOMENDAÇÕES DE AMOSTRAGEM:\n",
      "• Conjunto de dados pequeno - use o conjunto de dados completo ou validação cruzada cuidadosa\n",
      "• Tenha cuidado com o overfitting com dados limitados\n",
      "• Conjunto de dados com muito texto detectado - considere amostragem baseada em comprimento de texto\n",
      "• Recursos de alta cardinalidade detectados - garanta representação nas amostras\n"
     ]
    }
   ],
   "source": [
    "# 9. Amostragem e Estratégia de Subconjunto\n",
    "print(\"=== AMOSTRAGEM E ESTRATÉGIA DE SUBCONJUNTO ===\")\n",
    "\n",
    "print(f\"Tamanho do conjunto de dados: {len(df):,} linhas\")\n",
    "print(f\"Uso de memória: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Complexidade computacional estimada para diferentes tamanhos de amostra\n",
    "sample_sizes = [1000, 5000, 10000, 25000, 50000, 100000]\n",
    "for size in sample_sizes:\n",
    "    if size <= len(df):\n",
    "        percentage = (size / len(df)) * 100\n",
    "        print(f\"Amostra de {size:,} linhas = {percentage:.1f}% do conjunto de dados\")\n",
    "\n",
    "# Recomendar estratégia de amostragem com base nas características do conjunto de dados\n",
    "print(\"\\nRECOMENDAÇÕES DE AMOSTRAGEM:\")\n",
    "if len(df) > 100000:\n",
    "    print(\"• Considere amostragem estratificada para manter as distribuições de classes\")\n",
    "    print(\"• Comece com 10-20% da amostra para o desenvolvimento inicial do modelo\")\n",
    "    print(\"• Use amostragem progressiva: 1K → 10K → 50K → conjunto de dados completo\")\n",
    "elif len(df) > 10000:\n",
    "    print(\"• Conjunto de dados de tamanho médio - considere 20-50% da amostra para prototipagem\")\n",
    "    print(\"• Conjunto de dados completo gerenciável para a maioria dos algoritmos\")\n",
    "else:\n",
    "    print(\"• Conjunto de dados pequeno - use o conjunto de dados completo ou validação cruzada cuidadosa\")\n",
    "    print(\"• Tenha cuidado com o overfitting com dados limitados\")\n",
    "\n",
    "# Verificar se o conjunto de dados precisa de considerações especiais de amostragem\n",
    "text_heavy = any(df[col].dtype == 'object' and df[col].str.len().mean() > 500\n",
    "                for col in df.select_dtypes(include=['object']).columns)\n",
    "if text_heavy:\n",
    "    print(\"• Conjunto de dados com muito texto detectado - considere amostragem baseada em comprimento de texto\")\n",
    "\n",
    "high_cardinality = any(df[col].nunique() > len(df) * 0.1 \n",
    "                      for col in df.columns)\n",
    "if high_cardinality:\n",
    "    print(\"• Recursos de alta cardinalidade detectados - garanta representação nas amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "xpaiidmbcm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INSIGHTS PARA TREINAMENTO DE MODELOS ===\n",
      "RECOMENDAÇÕES DE ENGENHARIA DE FEATURES:\n",
      "• Recursos de texto detectados - considere:\n",
      "  - Vetorização TF-IDF\n",
      "  - Word embeddings (Word2Vec, GloVe, BERT)\n",
      "  - Comprimento do texto como recurso numérico\n",
      "  - Detecção de idioma se multilíngue\n",
      "\n",
      "RECOMENDAÇÕES DE SELEÇÃO DE MODELOS:\n",
      "Com base nas características do conjunto de dados:\n",
      "• Conjunto de dados médio → Métodos de ensemble (XGBoost, LightGBM, Random Forest)\n",
      "• Conjunto de dados com muito texto → Modelos Transformer (BERT, RoBERTa) ou arquiteturas CNN/RNN\n",
      "\n",
      "ESTRATÉGIA DE VALIDAÇÃO CRUZADA:\n",
      "• Use stratified k-fold (k=5) ou divisão treino/validação/teste\n",
      "\n",
      "MÉTRICAS CHAVE PARA ACOMPANHAR:\n",
      "• Curvas de perda de treinamento/validação\n",
      "• Precisão, Recall, F1-score por classe\n",
      "• Matriz de confusão para análise de erros\n",
      "• Importância de recursos/pesos de atenção\n",
      "• Tempo de treinamento e velocidade de inferência\n"
     ]
    }
   ],
   "source": [
    "# 10. Insights para Treinamento de Modelos\n",
    "print(\"=== INSIGHTS PARA TREINAMENTO DE MODELOS ===\")\n",
    "\n",
    "# Recomendações de engenharia de features\n",
    "print(\"RECOMENDAÇÕES DE ENGENHARIA DE FEATURES:\")\n",
    "\n",
    "text_cols = df.select_dtypes(include=['object']).columns\n",
    "if len(text_cols) > 0:\n",
    "    print(\"• Recursos de texto detectados - considere:\")\n",
    "    print(\"  - Vetorização TF-IDF\")\n",
    "    print(\"  - Word embeddings (Word2Vec, GloVe, BERT)\")\n",
    "    print(\"  - Comprimento do texto como recurso numérico\")\n",
    "    print(\"  - Detecção de idioma se multilíngue\")\n",
    "\n",
    "if len(numerical_columns) > 0:\n",
    "    print(\"• Recursos numéricos - considere:\")\n",
    "    print(\"  - Normalização/Padronização\")\n",
    "    print(\"  - Recursos polinomiais para relações não lineares\")\n",
    "    print(\"  - Binning para variáveis contínuas\")\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['category']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    print(\"• Recursos categóricos - considere:\")\n",
    "    print(\"  - One-hot encoding para baixa cardinalidade\")\n",
    "    print(\"  - Target encoding para alta cardinalidade\")\n",
    "    print(\"  - Embeddings para muito alta cardinalidade\")\n",
    "\n",
    "# Recomendações de seleção de modelos\n",
    "print(\"\\nRECOMENDAÇÕES DE SELEÇÃO DE MODELOS:\")\n",
    "print(\"Com base nas características do conjunto de dados:\")\n",
    "\n",
    "if len(df) < 1000:\n",
    "    print(\"• Conjunto de dados pequeno → Modelos simples (Regressão Logística, SVM, Random Forest)\")\n",
    "elif len(df) < 100000:\n",
    "    print(\"• Conjunto de dados médio → Métodos de ensemble (XGBoost, LightGBM, Random Forest)\")\n",
    "else:\n",
    "    print(\"• Conjunto de dados grande → Deep learning viável (Redes Neurais, Transformers)\")\n",
    "\n",
    "if text_heavy:\n",
    "    print(\"• Conjunto de dados com muito texto → Modelos Transformer (BERT, RoBERTa) ou arquiteturas CNN/RNN\")\n",
    "\n",
    "# Estratégia de validação cruzada\n",
    "print(\"\\nESTRATÉGIA DE VALIDAÇÃO CRUZADA:\")\n",
    "if len(df) < 1000:\n",
    "    print(\"• Use stratified k-fold (k=5 ou k=10)\")\n",
    "elif len(df) < 10000:\n",
    "    print(\"• Use stratified k-fold (k=5) ou divisão treino/validação/teste\")\n",
    "else:\n",
    "    print(\"• Divisão simples treino/validação/teste (70/15/15 ou 80/10/10)\")\n",
    "\n",
    "print(\"\\nMÉTRICAS CHAVE PARA ACOMPANHAR:\")\n",
    "print(\"• Curvas de perda de treinamento/validação\")\n",
    "print(\"• Precisão, Recall, F1-score por classe\")\n",
    "print(\"• Matriz de confusão para análise de erros\")\n",
    "print(\"• Importância de recursos/pesos de atenção\")\n",
    "print(\"• Tempo de treinamento e velocidade de inferência\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
