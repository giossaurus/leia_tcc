{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ef3fc8",
   "metadata": {},
   "source": [
    "### Treinamento e Validação com a Base Inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9cd18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f83a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CARREGAR E PREPARAR O SEED SET ANOTADO ---\n",
    "caminho_do_arquivo = '/Users/giossaurus/Developer/leia_tcc/data/processed/seed_set_anotado.csv'\n",
    "df_anotado = pd.read_csv(caminho_do_arquivo)\n",
    "df_anotado = df_anotado.rename(columns={'question': 'text', 'intent_choice': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f490c812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71eca4bc1a7c44d091fc80465718b880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mapear os rótulos de texto para números (IDs)\n",
    "labels = df_anotado['label'].unique().tolist()\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "df_anotado['label'] = df_anotado['label'].map(label2id)\n",
    "\n",
    "# Criar o dataset e configurar a coluna label como ClassLabel\n",
    "from datasets import ClassLabel\n",
    "full_seed_dataset = Dataset.from_pandas(df_anotado)\n",
    "\n",
    "# Converter a coluna label para ClassLabel para permitir estratificação\n",
    "features = full_seed_dataset.features.copy()\n",
    "features['label'] = ClassLabel(names=labels)\n",
    "full_seed_dataset = full_seed_dataset.cast(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f8d6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98278561664d0a97caa84ffe3d40b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DADOS ESTRATEGICAMENTE DIVIDIDOS ---\n",
      "Núcleo de Treinamento (Seed Train): 160 exemplos\n",
      "Conjunto de Teste Final (Guardado): 40 exemplos\n",
      "-> Para este Ciclo 1: Treino = 128, Validação = 32\n"
     ]
    }
   ],
   "source": [
    "# --- 2. DIVISÃO ESTRATÉGICA DOS DADOS ---\n",
    "# Dividir os 200 exemplos em Treino (80%) e Teste Final (20%)\n",
    "dataset_split = full_seed_dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)\n",
    "\n",
    "# Este é o nosso núcleo de treino, que vai crescer a cada ciclo\n",
    "seed_train_dataset = dataset_split[\"train\"]\n",
    "\n",
    "# ESTE É O NOSSO CONJUNTO DE TESTE FINAL. NÃO USAREMOS AGORA.\n",
    "final_test_dataset = dataset_split[\"test\"]\n",
    "# Salvar para uso futuro no final do projeto\n",
    "final_test_dataset.to_csv('/Users/giossaurus/Developer/leia_tcc/data/processed/final_test_set.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"--- DADOS ESTRATEGICAMENTE DIVIDIDOS ---\")\n",
    "print(f\"Núcleo de Treinamento (Seed Train): {len(seed_train_dataset)} exemplos\")\n",
    "print(f\"Conjunto de Teste Final (Guardado): {len(final_test_dataset)} exemplos\")\n",
    "\n",
    "# Criar um conjunto de validação a partir do núcleo de treino para monitorar este ciclo\n",
    "train_val_split = seed_train_dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)\n",
    "train_dataset = train_val_split[\"train\"]\n",
    "eval_dataset = train_val_split[\"test\"]\n",
    "\n",
    "print(f\"-> Para este Ciclo 1: Treino = {len(train_dataset)}, Validação = {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8804ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fb8589d8d143e7bb5c2ff2078ccf09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff8325ba2b54125b55fe747d4a2b407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. PREPARAR O MODELO E TOKENIZADOR ---\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=len(labels), \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eccfe07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/x1x0j4qs0svb48fpvhhvkmbh0000gn/T/ipykernel_13211/771060541.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INICIANDO TREINAMENTO DO MODELO v1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.276618</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.218083</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.143623</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.459150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.092624</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.459150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.074675</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.483254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TREINAMENTO CONCLUÍDO ---\n"
     ]
    }
   ],
   "source": [
    "# --- 4. CONFIGURAR E EXECUTAR O TREINAMENTO ---\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    \n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1[\"f1\"]}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/leia_classifier_cycle1\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"\\n--- INICIANDO TREINAMENTO DO MODELO v1 ---\")\n",
    "trainer.train()\n",
    "print(\"\\n--- TREINAMENTO CONCLUÍDO ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fc9e780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo v1 salvo em './models/leia_classifier_v1_final'\n"
     ]
    }
   ],
   "source": [
    "# Salvar o modelo e o tokenizador deste ciclo\n",
    "trainer.save_model(\"./models/leia_classifier_v1_final\")\n",
    "print(\"Modelo v1 salvo em './models/leia_classifier_v1_final'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
