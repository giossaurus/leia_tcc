{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e963fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e4c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de exemplos anotados manualmente: 1001\n"
     ]
    }
   ],
   "source": [
    "# --- 1. CARREGAR E CONSOLIDAR TODOS OS DADOS ANOTADOS MANUALMENTE ---\n",
    "\n",
    "# Caminhos para todos os arquivos que você anotou\n",
    "path_seed_set = '/Users/giossaurus/Developer/leia_tcc/data/processed/seed_set_anotado.csv'\n",
    "path_cycle1 = '/Users/giossaurus/Developer/leia_tcc/data/processed/active_learning_cycle1.csv'\n",
    "path_cycle2 = '/Users/giossaurus/Developer/leia_tcc/data/processed/active_learning_cycle2.csv'\n",
    "# AJUSTE AQUI se o nome do seu último arquivo for diferente\n",
    "path_lote_final = '/Users/giossaurus/Developer/leia_tcc/data/processed/anotacao_maior_final.csv' \n",
    "\n",
    "# Carregar todos os dataframes\n",
    "df_seed = pd.read_csv(path_seed_set)\n",
    "df_c1 = pd.read_csv(path_cycle1)\n",
    "df_c2 = pd.read_csv(path_cycle2)\n",
    "df_final = pd.read_csv(path_lote_final)\n",
    "\n",
    "# Juntar todos em um único dataframe\n",
    "df_full_manual = pd.concat([df_seed, df_c1, df_c2, df_final], ignore_index=True)\n",
    "\n",
    "# Remover duplicatas caso algum exemplo tenha sido incluído em mais de um lote\n",
    "df_full_manual.drop_duplicates(subset=['question_id'], inplace=True)\n",
    "\n",
    "print(f\"Total de exemplos anotados manualmente: {len(df_full_manual)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c22e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivos individuais...\n",
      "\n",
      "Seed set:\n",
      "  - Linhas totais: 200\n",
      "  - Colunas disponíveis: ['annotation_id', 'annotator', 'created_at', 'disciplina', 'id', 'intent_choice', 'lead_time', 'question', 'question_id', 'split', 'true_answer', 'updated_at']\n",
      "  - Coluna texto encontrada: question\n",
      "  - Coluna label encontrada: intent_choice\n",
      "  - Exemplos adicionados: 200\n",
      "\n",
      "Cycle1:\n",
      "  - Linhas totais: 50\n",
      "  - Colunas disponíveis: ['annotation_id', 'annotator', 'created_at', 'disciplina', 'id', 'intent_choice', 'lead_time', 'question', 'question_id', 'split', 'text', 'true_answer', 'uncertainty', 'updated_at']\n",
      "  - Coluna texto encontrada: question\n",
      "  - Coluna label encontrada: intent_choice\n",
      "  - Exemplos adicionados: 50\n",
      "\n",
      "Cycle2:\n",
      "  - Linhas totais: 50\n",
      "  - Colunas disponíveis: ['annotation_id', 'annotator', 'created_at', 'disciplina', 'id', 'intent_choice', 'lead_time', 'question', 'question_id', 'split', 'text', 'true_answer', 'uncertainty', 'updated_at']\n",
      "  - Coluna texto encontrada: question\n",
      "  - Coluna label encontrada: intent_choice\n",
      "  - Exemplos adicionados: 50\n",
      "\n",
      "Lote final:\n",
      "  - Linhas totais: 701\n",
      "  - Colunas disponíveis: ['annotation_id', 'annotator', 'created_at', 'disciplina', 'id', 'intent_choice', 'lead_time', 'question', 'question_id', 'split', 'true_answer', 'updated_at']\n",
      "  - Coluna texto encontrada: question\n",
      "  - Coluna label encontrada: intent_choice\n",
      "  - Exemplos adicionados: 699\n",
      "\n",
      "=== RESUMO ===\n",
      "Total de exemplos extraídos: 999\n",
      "Por arquivo: Seed=200, Cycle1=50, Cycle2=50, Final=699\n",
      "Esperado: 1001, Atual: 999, Diferença: 2\n",
      "\n",
      "Distribuição por fonte:\n",
      "source\n",
      "Lote final    699\n",
      "Seed set      200\n",
      "Cycle1         50\n",
      "Cycle2         50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Removidas 0 duplicatas por question_id\n",
      "Total de exemplos após remoção de duplicatas: 999\n",
      "\n",
      "Labels únicos encontrados: ['Análise de Exemplo', 'Comparativo', 'Conceitual', 'Procedimental']\n",
      "Labels mapeados: ['Análise de Exemplo', 'Conceitual', 'Procedimental', 'Comparativo']\n",
      "Dataset final limpo: 999 exemplos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8228ac7ac00b44e8ae0736e71730d896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 2. PREPARAR O DATASET FINAL ---\n",
    "\n",
    "# Vamos processar cada arquivo separadamente para evitar problemas de índice\n",
    "all_data = []\n",
    "\n",
    "print(\"Processando arquivos individuais...\")\n",
    "\n",
    "# Função auxiliar para processar cada dataframe\n",
    "def process_dataframe(df, name):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  - Linhas totais: {len(df)}\")\n",
    "    print(f\"  - Colunas disponíveis: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Mapear possíveis nomes de colunas\n",
    "    text_cols = ['question', 'text']\n",
    "    label_cols = ['intent_choice', 'label']\n",
    "    \n",
    "    # Encontrar a coluna de texto\n",
    "    text_col = None\n",
    "    for col in text_cols:\n",
    "        if col in df.columns:\n",
    "            text_col = col\n",
    "            break\n",
    "    \n",
    "    # Encontrar a coluna de label\n",
    "    label_col = None\n",
    "    for col in label_cols:\n",
    "        if col in df.columns:\n",
    "            label_col = col\n",
    "            break\n",
    "    \n",
    "    print(f\"  - Coluna texto encontrada: {text_col}\")\n",
    "    print(f\"  - Coluna label encontrada: {label_col}\")\n",
    "    \n",
    "    if not text_col or not label_col:\n",
    "        print(f\"  - ERRO: Colunas essenciais não encontradas\")\n",
    "        return 0\n",
    "    \n",
    "    # Extrair dados diretamente sem operações de pandas que podem causar reindexing\n",
    "    added_count = 0\n",
    "    \n",
    "    # Usar .iloc para evitar problemas de índice\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            # Acessar por posição para evitar problemas de índice\n",
    "            text_val = df.iloc[i][text_col]\n",
    "            label_val = df.iloc[i][label_col]\n",
    "            question_id = df.iloc[i].get('question_id', f\"{name}_{i}\")\n",
    "            \n",
    "            # Verificação mais permissiva\n",
    "            if pd.notna(text_val) and pd.notna(label_val) and str(text_val).strip() and str(label_val).strip():\n",
    "                all_data.append({\n",
    "                    'text': str(text_val).strip(),\n",
    "                    'label': str(label_val).strip(),\n",
    "                    'question_id': str(question_id) if pd.notna(question_id) else f\"{name}_{i}\",\n",
    "                    'source': name\n",
    "                })\n",
    "                added_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  - Erro na linha {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"  - Exemplos adicionados: {added_count}\")\n",
    "    return added_count\n",
    "\n",
    "# Processar cada arquivo\n",
    "try:\n",
    "    count1 = process_dataframe(df_seed, \"Seed set\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro no seed set: {e}\")\n",
    "    count1 = 0\n",
    "\n",
    "try:\n",
    "    count2 = process_dataframe(df_c1, \"Cycle1\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro no cycle1: {e}\")\n",
    "    count2 = 0\n",
    "\n",
    "try:\n",
    "    count3 = process_dataframe(df_c2, \"Cycle2\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro no cycle2: {e}\")\n",
    "    count3 = 0\n",
    "\n",
    "try:\n",
    "    count4 = process_dataframe(df_final, \"Lote final\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro no lote final: {e}\")\n",
    "    count4 = 0\n",
    "\n",
    "print(f\"\\n=== RESUMO ===\")\n",
    "print(f\"Total de exemplos extraídos: {len(all_data)}\")\n",
    "print(f\"Por arquivo: Seed={count1}, Cycle1={count2}, Cycle2={count3}, Final={count4}\")\n",
    "print(f\"Esperado: 1001, Atual: {len(all_data)}, Diferença: {1001 - len(all_data)}\")\n",
    "\n",
    "# Criar um novo dataframe limpo a partir dos dados extraídos\n",
    "df_full_manual = pd.DataFrame(all_data)\n",
    "\n",
    "# Mostrar distribuição por fonte\n",
    "if 'source' in df_full_manual.columns:\n",
    "    print(f\"\\nDistribuição por fonte:\")\n",
    "    print(df_full_manual['source'].value_counts())\n",
    "\n",
    "# Remover duplicatas por question_id se disponível\n",
    "if 'question_id' in df_full_manual.columns:\n",
    "    initial_size = len(df_full_manual)\n",
    "    df_full_manual = df_full_manual.drop_duplicates(subset=['question_id'])\n",
    "    print(f\"\\nRemovidas {initial_size - len(df_full_manual)} duplicatas por question_id\")\n",
    "\n",
    "print(f\"Total de exemplos após remoção de duplicatas: {len(df_full_manual)}\")\n",
    "\n",
    "# Manter apenas text e label para o modelo\n",
    "df_final_clean = df_full_manual[['text', 'label']].copy()\n",
    "\n",
    "# Verificar labels únicos antes do mapeamento\n",
    "print(f\"\\nLabels únicos encontrados: {sorted(df_final_clean['label'].unique())}\")\n",
    "\n",
    "# Mapear rótulos para IDs\n",
    "labels = df_final_clean['label'].unique().tolist()\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Aplicar mapeamento\n",
    "df_final_clean['label'] = df_final_clean['label'].map(label2id)\n",
    "unmapped_labels = df_final_clean['label'].isna().sum()\n",
    "if unmapped_labels > 0:\n",
    "    print(f\"AVISO: {unmapped_labels} labels não puderam ser mapeados\")\n",
    "\n",
    "df_final_clean.dropna(subset=['label'], inplace=True)\n",
    "df_final_clean['label'] = df_final_clean['label'].astype(int)\n",
    "\n",
    "print(f\"Labels mapeados: {labels}\")\n",
    "print(f\"Dataset final limpo: {len(df_final_clean)} exemplos\")\n",
    "\n",
    "# Converter para Dataset do Hugging Face\n",
    "from datasets import ClassLabel\n",
    "full_dataset = Dataset.from_pandas(df_final_clean)\n",
    "\n",
    "# Configurar ClassLabel para estratificação\n",
    "features = full_dataset.features.copy()\n",
    "features['label'] = ClassLabel(names=labels)\n",
    "full_dataset = full_dataset.cast(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91beaef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset de Treino: 639 exemplos\n",
      "Dataset de Validação: 160 exemplos\n",
      "Dataset de Teste Final: 200 exemplos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. DIVISÃO ESTRATÉGICA: TREINO E TESTE ---\n",
    "# Com 1000 exemplos, podemos criar um conjunto de teste robusto (20%)\n",
    "dataset_split = full_dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)\n",
    "train_dataset_full = dataset_split[\"train\"]\n",
    "test_dataset = dataset_split[\"test\"]\n",
    "\n",
    "# Dividir o treino novamente para ter um conjunto de validação durante o treino\n",
    "train_val_split = train_dataset_full.train_test_split(test_size=0.2, stratify_by_column=\"label\", seed=42)\n",
    "train_dataset = train_val_split[\"train\"]\n",
    "eval_dataset = train_val_split[\"test\"]\n",
    "\n",
    "print(f\"\\nDataset de Treino: {len(train_dataset)} exemplos\")\n",
    "print(f\"Dataset de Validação: {len(eval_dataset)} exemplos\")\n",
    "print(f\"Dataset de Teste Final: {len(test_dataset)} exemplos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5c65e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a88b92a2a61494d855304fdc9dde104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/639 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d880af747eb402ab230494867a08d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6346469234e4b7484f0d7b97f0c6e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/k4/x1x0j4qs0svb48fpvhhvkmbh0000gn/T/ipykernel_51419/4094535796.py:43: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# --- 4. PREPARAR MODELO, TOKENIZER E TREINAMENTO ---\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1[\"f1\"]}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/Users/giossaurus/Developer/leia_tcc/models/leia_classifier_1k_base\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5, # Com mais dados, 5 épocas é um bom ponto de partida\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b55de872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INICIANDO TREINAMENTO DO MODELO DE BASE (1k) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 03:48, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988830</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.488910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.826912</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.613797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.767434</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.678288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.750718</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.686288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.759789</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.685151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TREINAMENTO CONCLUÍDO ---\n",
      "\n",
      "--- AVALIANDO PERFORMANCE FINAL NO CONJUNTO DE TESTE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch-mps/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTADOS FINAIS (NO CONJUNTO DE TESTE) ---\n",
      "Acurácia Final: 0.7200\n",
      "F1-Score Final (Ponderado): 0.6982\n",
      "-------------------------------------------------\n",
      "Modelo final salvo em '/Users/giossaurus/Developer/leia_tcc/models/leia_classifier_1k_final'\n"
     ]
    }
   ],
   "source": [
    "# --- 5. TREINAR E AVALIAR ---\n",
    "\n",
    "print(\"\\n--- INICIANDO TREINAMENTO DO MODELO DE BASE (1k) ---\")\n",
    "trainer.train()\n",
    "print(\"\\n--- TREINAMENTO CONCLUÍDO ---\")\n",
    "\n",
    "print(\"\\n--- AVALIANDO PERFORMANCE FINAL NO CONJUNTO DE TESTE ---\")\n",
    "final_results = trainer.evaluate(eval_dataset=tokenized_test_dataset)\n",
    "\n",
    "print(\"\\n--- RESULTADOS FINAIS (NO CONJUNTO DE TESTE) ---\")\n",
    "print(f\"Acurácia Final: {final_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-Score Final (Ponderado): {final_results['eval_f1']:.4f}\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "# Salvar o modelo final\n",
    "trainer.save_model(\"/Users/giossaurus/Developer/leia_tcc/models/leia_classifier_1k_final\")\n",
    "print(\"Modelo final salvo em '/Users/giossaurus/Developer/leia_tcc/models/leia_classifier_1k_final'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
